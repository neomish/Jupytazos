{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba del modelo largo de lengaje Dolly-v2-3b\n",
        "\n",
        "1. Modelo de lengaje entrenado: Dolly-v2-3b\n",
        "1. Numero de parametro que posee: 3 Billones\n",
        "1. Tipo de entrenamiento: Modelo Instruction-tuned\n",
        "1. Link: https://huggingface.co/databricks/dolly-v2-3b"
      ],
      "metadata": {
        "id": "EH3miCp10HBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder utilizar el modelo entrenado de Dolly se necesitan instalar liber칤as en el sistema operativo... pero, este sistema es una m치quina virtual que est치 limitada por el tiempo permitido de uso de un procesador"
      ],
      "metadata": {
        "id": "WGePjni0AXgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se necesita un procesador que permita realizar operaciones especiales con el modelo, es necesario un acelerador de procesamiento gr치fico, como el de las tarejetas de aceleraci칩n gr치fica para los videojuegos, se debe elegir T4 GPU en el entorno de ejecuci칩n."
      ],
      "metadata": {
        "id": "nO2OWpOpGFNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Herramientas de apoyo"
      ],
      "metadata": {
        "id": "H11XjKrNDxg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformers** es una librer칤a que facilita el uso de los modelos largos de lenguajes, **sentencepiece** es otra herramientaque que permite codificar y decodificar en tokens las consultas que se le hacen a un modelo largo de lenguaje, y **accelerate** permite detectar autom치ticamente el tipo de configuraci칩n distribuida que se tiene disponible en una m치quina virtual e inicializar치 todos los componentes necesarios para el uso de un modelo largo de lenguaje."
      ],
      "metadata": {
        "id": "Bw6dpX4cIDhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas herramientas no est치n instaladas en el entorno virtual, y por eso se debe proceder a instalar las liber칤as para su uso con Python, eso se hace con el administrador de paquetes pip"
      ],
      "metadata": {
        "id": "BPRDTmM4Jmy_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "is4QL94nz3He"
      },
      "outputs": [],
      "source": [
        "# Instalaci칩n de paquetes de python en la m치quina virtual\n",
        "# 游뱅 Transformers proporciona APIs para descargar y entrenar f치cilmente modelos preentrenados de 칰ltima generaci칩n\n",
        "!pip install transformers\n",
        "# API que ofrece ofrecer치 codificaci칩n, decodificaci칩n y entrenamiento de una herramienta de lenguaje\n",
        "!pip install sentencepiece\n",
        "# Biblioteca que permite ejecutar el mismo c칩digo de PyTorch, que simplifica el entrenamiento y la inferencia\n",
        "!pip install accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrar las herramientas necesarias"
      ],
      "metadata": {
        "id": "S1xkUxsVD8vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo las herramientas listas para usarse en los c칩digos fuente de los programas de Python ya se puede utilizar las liber칤as, para ello se importan en los programas a crear para su uso"
      ],
      "metadata": {
        "id": "nEUBxbjdLDou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librer칤as\n",
        "import torch                        # Activar computaci칩n de Tensores con aceleraci칩n de GPU\n",
        "from transformers import pipeline   # Atajo para usar modelos pre-entrenados para inferencia\n",
        "import os                           # Permite interactuar con instrucciones de entrada y salida del sistema operativo"
      ],
      "metadata": {
        "id": "zAPe_kif4Kls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descarga del modelo de Dolly"
      ],
      "metadata": {
        "id": "G0Onn717EGBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las herramientas para trabajar modelos largos de lenguaje falta tener un modelo para usar, as칤 que se debe descargar un modelo y usar una de las herramientas para conectarse e interactuar con 칠l"
      ],
      "metadata": {
        "id": "xz4cnjnPLVzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga el modelo de dolly y carga el modelo en la variable dolly_pipeline\n",
        "dolly_pipeline = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "y-3aEl1D5E9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facilitando el uso del modelo Dolly"
      ],
      "metadata": {
        "id": "LbQN2SK0EQXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para facilitar la interacci칩n con el modelo sin utilizar par치metros complejos y preparaciones cada vez que se quiera utilizar es buena idea crear una funci칩n, una forma de consultar al modelo las preguntas que se quieran y obtener una respuesta que se pueda entender"
      ],
      "metadata": {
        "id": "OenpvbM-L_Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir una funci칩n con la cual preguntarle al modelo mediante una consulta\n",
        "def preguntar_a_dolly( consulta ):\n",
        "    # Se usa una variable para definir el token fundador\n",
        "    token_fundador = \"\"\"\n",
        "    Eres un experto en matem치tica.\n",
        "    Eres muy bueno explicando conceptos de matem치tica.\n",
        "    Ayuda al usuario dando una respuesta comprensible.\n",
        "    \"\"\"\n",
        "    # Se crea una variable auxiliar para mostrar lineas divisorias\n",
        "    divisor = f\"-------------------------------------------\\n\"\n",
        "    # Se utiliza la tuber칤a para preguntarle a dolly uniendo el token fundador con la consulta\n",
        "    dolly_responde = dolly_pipeline( token_fundador + consulta, max_new_tokens = 500 )\n",
        "    # La respuesta queda almacenada en un arreglo, por lo que se guarda solo el texto generado\n",
        "    respuesta_generada = dolly_responde[ 0 ][ \"generated_text\" ]\n",
        "    # Se muestran los textos de manera ordenada y creativa para depurado del uso\n",
        "    print( f\"{divisor}Token fundador     : {token_fundador}\"       )\n",
        "    print( f\"{divisor}Consulta           : \\n{consulta}\"           )\n",
        "    print( f\"{divisor}Respuesta de Dolly : \\n{respuesta_generada}\" )\n",
        "    # se devuelve solo la respuesta para usos adicionales hacia donde fue solicitada\n",
        "    return respuesta_generada"
      ],
      "metadata": {
        "id": "JQNxJIia6ktg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probando el funcionamiento"
      ],
      "metadata": {
        "id": "8DXaLD4IEgnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se usa una interfaz de IA del tipo de modelo largo de lenguaje se usa un texto al que denominamos prompt (*una instrucci칩n de entrada*) que se le env칤a al modelo, y del cual se obtiene una respuesta, para probar ese comportamiento se codificar치 con variables la interacci칩n con el modelo a travez de la funci칩n creada"
      ],
      "metadata": {
        "id": "m82r8mAdM9mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el prompt de consulta\n",
        "prompt = \"쯈u칠 es un tensor en matem치tica?\"\n",
        "# Obtener la respuesta de dolly\n",
        "respuesta = preguntar_a_dolly( prompt )"
      ],
      "metadata": {
        "id": "oiMMxi__93Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La prueba es buena, se pueden hacer mas pruebas cambiando en la funci칩n el token generador (*modificandolo y ejecutando el bloque*) y luego modificando el prompt en la prueba (*y ejecutando el bloque*)"
      ],
      "metadata": {
        "id": "5VzRveYLOVuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lanz치ndola a la web"
      ],
      "metadata": {
        "id": "ZgFgnxB3E-Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las formas en las que actualmente usamos las IA es mediante interfaces gr치ficas web, para que sea m치s pr치ctico y que m치s personas puedan usarla"
      ],
      "metadata": {
        "id": "zvGzq1rPPUNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando la herramienta para crear aplicaciones web"
      ],
      "metadata": {
        "id": "VBu2Y_URFWMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se necesitar치 una herramienta que facilite crear interfaces amigables de tipo web, y **gradio** es otra librer칤a que se puede utilizar para facilitar esa tarea, se instala con el administrador de paquetes pip"
      ],
      "metadata": {
        "id": "29twq6POQlQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar otro paquete para python en la m치quina virtual\n",
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wfY-IzN5AiIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrando las herramientas para la web"
      ],
      "metadata": {
        "id": "RlYThJ2JFmeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizarla se importar치 como una liber칤a, pero tambi칠n se necesita otra librer칤a especial para indicarle que la codificaci칩n del texto debe ser aceptable y con s칤mbolos reconocibles en la web (*UTF-8*)"
      ],
      "metadata": {
        "id": "936hqdheRbPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar\n",
        "import locale        # Librer칤a de configuraci칩n formato de car치cteres para la web\n",
        "import gradio as gr  # Librer칤a que facilita la creaci칩n de aplicaciones web"
      ],
      "metadata": {
        "id": "m7_PrUQ6A59U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eligiendo la codificaci칩n de textos de la aplicaci칩n web"
      ],
      "metadata": {
        "id": "iXtRzr6FHvLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se debe indicar que se usar치 la codificaci칩n especial UTF-8 a todos los textos que se generen para ser mostrados y utilizados en las interfaces web."
      ],
      "metadata": {
        "id": "XvxQCcbRRyaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la codificaci칩n de caract칠res a utilizar con el formato UTF-8\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n"
      ],
      "metadata": {
        "id": "0p8A94LJBh23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dise침ando la interfaz de la aplicaci칩n web"
      ],
      "metadata": {
        "id": "_I8IbXJmH2PW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder crear una interfaz web lo correcto es dise침ar primero la idea:\n",
        "* Se necesitar치 inicialmente un espacio (textarea) para poder escribir el prompt de entrada\n",
        "* Tambi칠n deber치 existir un espacio (textarea) para que se pueda leer la respuesta\n",
        "* Asingar un t칤tulo no es mala idea, identificar치 a la aplicaci칩n web\n",
        "* Y tambi칠n una descripci칩n de la aplicaci칩n para darle elegancia\n",
        "* Se puede indicar como ser칤an unos ejemplos de prompt a utiizar\n",
        "\n",
        "Todos estos elementos ser치n 칰tiles, pero realmente, lo mas importante es saber a que funci칩n se le har치 responsable de recibir los valores, y que tambi칠n nos devolver치 una respuesta, la funci칩n a utilizar ser치 la que se denomin칩 como **preguntar_a_dolly**\n",
        "\n"
      ],
      "metadata": {
        "id": "51aMnPsGSPwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dise침o de la aplicaci칩n web\n",
        "# Una variable que definir치 una caja para introducir texto\n",
        "caja_de_entrada  = gr.Textbox( label = \"Escribe Prompt Aqui\" , lines = 6 )\n",
        "# Otra variable que definir치 una caja para mostrar texto\n",
        "caja_de_salida   = gr.Textbox( label = \"Respuesta\"           , lines = 3 )\n",
        "# Una variable m치s para darle un t칤tulo a la aplicaci칩n web\n",
        "titulo_de_mi_app = \"Mi tutor IA de matem치ticas\"\n",
        "# Podr칤a ser 칰til usar una variable para mostrar la descripci칩n de la aplicaci칩n\n",
        "descripcion_app  = \"Herramienta para aprender de matem치ticas con Dolly\"\n",
        "# Un conjunto de ejemplos para poder utilizar como entradas de textos\n",
        "ejemplos         = [\n",
        "    \"Explicame el teorema de Pit치goras\",\n",
        "    \"Expl칤came la suma de Gauss\"\n",
        "]\n",
        "# La agrupaci칩n de todo en una sola interfaz de gradio\n",
        "interfaz = gr.Interface(\n",
        "    fn             = preguntar_a_dolly   ,\n",
        "    inputs         = [ caja_de_entrada ] ,\n",
        "    outputs        = [ caja_de_salida  ] ,\n",
        "    title          = titulo_de_mi_app    ,\n",
        "    description    = descripcion_app     ,\n",
        "    examples       = ejemplos            ,\n",
        "    allow_flagging = \"never\"               # Desaparece un bot칩n llamado Flag\n",
        ")"
      ],
      "metadata": {
        "id": "5i3eqkWHCHeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando la aplicaci칩n web\n",
        "\n"
      ],
      "metadata": {
        "id": "8EMQONFlIQlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dise침o que ya est치 listo debe ser ejecutado y puede ser tambi칠n publicado, la herramienta grado permite utilziar la interfaz creada a travez de un tunel, publicando la interfaz y haciendola accesible a mas usuarios a trav칠s de Internet por lo que brindar치 una url para poder compartirla"
      ],
      "metadata": {
        "id": "ztqKbhhXTsYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lanzamiento de la aplicaci칩n web\n",
        "interfaz.launch( share = True )"
      ],
      "metadata": {
        "id": "NYXB4e54DQt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalizando la aplicaci칩n web"
      ],
      "metadata": {
        "id": "YjM80WEAIbeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando ya se ha probado la aplicaci칩n es correcto detener el servicio para que no se desperdicie el tiempo de uso, tanto de las unidades de CPU de Google Colab, como el servicio de publicaci칩n de la herramienta del tunel al sitio de gradio"
      ],
      "metadata": {
        "id": "9cwB-HOiVcMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detener la aplciaci칩n web\n",
        "interfaz.close()"
      ],
      "metadata": {
        "id": "ZVyKACGfEpC8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}