{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "EH3miCp10HBK",
        "H11XjKrNDxg9",
        "S1xkUxsVD8vh",
        "G0Onn717EGBC",
        "LbQN2SK0EQXb",
        "8DXaLD4IEgnc",
        "ZgFgnxB3E-Ju",
        "VBu2Y_URFWMP",
        "RlYThJ2JFmeL",
        "iXtRzr6FHvLS",
        "_I8IbXJmH2PW",
        "8EMQONFlIQlX",
        "YjM80WEAIbeZ",
        "FT-lsPol2dgd",
        "5Z46Neha83Ik",
        "dFzOKRTg89X9",
        "ixUp1N_H9G8j",
        "M4kgBJlA9TCx"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prueba del modelo largo de lenguaje Dolly-v2-3b\n",
        "\n",
        "1. Modelo de lenguaje entrenado: Dolly-v2-3b\n",
        "1. Numero de parametro que posee: 3 Billones\n",
        "1. Tipo de entrenamiento: Modelo Instruction-tuned\n",
        "1. Link: https://huggingface.co/databricks/dolly-v2-3b"
      ],
      "metadata": {
        "id": "EH3miCp10HBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder utilizar el modelo entrenado de Dolly se necesitan instalar liberías en el sistema operativo... pero, este sistema es una máquina virtual que está limitada por el tiempo permitido de uso de un procesador"
      ],
      "metadata": {
        "id": "WGePjni0AXgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se necesita un procesador que permita realizar operaciones especiales con el modelo, es necesario un acelerador de procesamiento gráfico, como el de las tarejetas de aceleración gráfica para los videojuegos, se debe elegir T4 GPU en el entorno de ejecución."
      ],
      "metadata": {
        "id": "nO2OWpOpGFNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Herramientas de apoyo"
      ],
      "metadata": {
        "id": "H11XjKrNDxg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transformers** es una librería que facilita el uso de los modelos largos de lenguajes, **sentencepiece** es otra herramientaque que permite codificar y decodificar en tokens las consultas que se le hacen a un modelo largo de lenguaje, y **accelerate** permite detectar automáticamente el tipo de configuración distribuida que se tiene disponible en una máquina virtual e inicializará todos los componentes necesarios para el uso de un modelo largo de lenguaje."
      ],
      "metadata": {
        "id": "Bw6dpX4cIDhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas herramientas actualmente ya están instaladas en el entorno virtual, y por eso ya no se debe proceder a instalar las liberías para su uso con Python, eso se antes se hacía con el administrador de paquetes pip\n",
        "\n",
        "```\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install accelerate\n",
        "```"
      ],
      "metadata": {
        "id": "BPRDTmM4Jmy_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrar las herramientas necesarias"
      ],
      "metadata": {
        "id": "S1xkUxsVD8vh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo las herramientas listas para usarse en los códigos fuente de los programas de Python ya se puede utilizar las liberías, para ello se importan en los programas a crear para su uso"
      ],
      "metadata": {
        "id": "nEUBxbjdLDou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar librerías\n",
        "import torch                        # Activar computación de Tensores con aceleración de GPU\n",
        "from transformers import pipeline   # Atajo para usar modelos pre-entrenados para inferencia\n",
        "import os                           # Permite interactuar con instrucciones de entrada y salida del sistema operativo"
      ],
      "metadata": {
        "id": "zAPe_kif4Kls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descarga del modelo de Dolly"
      ],
      "metadata": {
        "id": "G0Onn717EGBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las herramientas para trabajar modelos largos de lenguaje falta tener un modelo para usar, así que se debe descargar un modelo y usar una de las herramientas para conectarse e interactuar con él"
      ],
      "metadata": {
        "id": "xz4cnjnPLVzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga el modelo de dolly y carga el modelo en la variable dolly_pipeline\n",
        "dolly_pipeline = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "y-3aEl1D5E9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Facilitando el uso del modelo Dolly"
      ],
      "metadata": {
        "id": "LbQN2SK0EQXb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para facilitar la interacción con el modelo sin utilizar parámetros complejos y preparaciones cada vez que se quiera utilizar es buena idea crear una función, una forma de consultar al modelo las preguntas que se quieran y obtener una respuesta que se pueda entender"
      ],
      "metadata": {
        "id": "OenpvbM-L_Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir una función con la cual preguntarle al modelo mediante una consulta\n",
        "def preguntar_a_dolly( consulta ):\n",
        "    # Se usa una variable para definir el token fundador\n",
        "    token_fundador = \"\"\"\n",
        "    Eres un experto en matemática.\n",
        "    Eres muy bueno explicando conceptos de matemática.\n",
        "    Ayuda al usuario dando una respuesta comprensible.\n",
        "    \"\"\"\n",
        "    # Se crea una variable auxiliar para mostrar lineas divisorias\n",
        "    divisor = f\"-------------------------------------------\\n\"\n",
        "    # Se utiliza la tubería para preguntarle a dolly uniendo el token fundador con la consulta\n",
        "    dolly_responde = dolly_pipeline( token_fundador + consulta, max_new_tokens = 500 )\n",
        "    # La respuesta queda almacenada en un arreglo, por lo que se guarda solo el texto generado\n",
        "    respuesta_generada = dolly_responde[ 0 ][ \"generated_text\" ]\n",
        "    # Se muestran los textos de manera ordenada y creativa para depurado del uso\n",
        "    print( f\"{divisor}Token fundador     : {token_fundador}\"       )\n",
        "    print( f\"{divisor}Consulta           : \\n{consulta}\"           )\n",
        "    print( f\"{divisor}Respuesta de Dolly : \\n{respuesta_generada}\" )\n",
        "    # se devuelve solo la respuesta para usos adicionales hacia donde fue solicitada\n",
        "    return respuesta_generada"
      ],
      "metadata": {
        "id": "JQNxJIia6ktg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probando el funcionamiento"
      ],
      "metadata": {
        "id": "8DXaLD4IEgnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se usa una interfaz de IA del tipo de modelo largo de lenguaje se usa un texto al que denominamos prompt (*una instrucción de entrada*) que se le envía al modelo, y del cual se obtiene una respuesta, para probar ese comportamiento se codificará con variables la interacción con el modelo a travez de la función creada"
      ],
      "metadata": {
        "id": "m82r8mAdM9mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el prompt de consulta\n",
        "prompt = \"¿Qué es un tensor en matemática?\"\n",
        "# Obtener la respuesta de dolly\n",
        "respuesta = preguntar_a_dolly( prompt )"
      ],
      "metadata": {
        "id": "oiMMxi__93Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La prueba es buena, se pueden hacer mas pruebas cambiando en la función el token generador (*modificandolo y ejecutando el bloque*) y luego modificando el prompt en la prueba (*y ejecutando el bloque*)"
      ],
      "metadata": {
        "id": "5VzRveYLOVuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lanzándola a la web"
      ],
      "metadata": {
        "id": "ZgFgnxB3E-Ju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las formas en las que actualmente usamos las IA es mediante interfaces gráficas web, para que sea más práctico y que más personas puedan usarla"
      ],
      "metadata": {
        "id": "zvGzq1rPPUNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalando la herramienta para crear aplicaciones web"
      ],
      "metadata": {
        "id": "VBu2Y_URFWMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se necesitará una herramienta que facilite crear interfaces amigables de tipo web, y **gradio** es otra librería que se puede utilizar para facilitar esa tarea, se instala con el administrador de paquetes pip una versión en particular"
      ],
      "metadata": {
        "id": "29twq6POQlQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "V9AaAXwHoBJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrando las herramientas para la web"
      ],
      "metadata": {
        "id": "RlYThJ2JFmeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizarla se importará como una libería, pero también se necesita otra librería especial para indicarle que la codificación del texto debe ser aceptable y con símbolos reconocibles en la web (*UTF-8*)"
      ],
      "metadata": {
        "id": "936hqdheRbPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar\n",
        "import locale        # Librería de configuración formato de carácteres para la web\n",
        "import gradio as gr  # Librería que facilita la creación de aplicaciones web"
      ],
      "metadata": {
        "id": "m7_PrUQ6A59U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eligiendo la codificación de textos de la aplicación web"
      ],
      "metadata": {
        "id": "iXtRzr6FHvLS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se debe indicar que se usará la codificación especial UTF-8 a todos los textos que se generen para ser mostrados y utilizados en las interfaces web."
      ],
      "metadata": {
        "id": "XvxQCcbRRyaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la codificación de caractéres a utilizar con el formato UTF-8\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n"
      ],
      "metadata": {
        "id": "0p8A94LJBh23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diseñando la interfaz de la aplicación web"
      ],
      "metadata": {
        "id": "_I8IbXJmH2PW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder crear una interfaz web lo correcto es diseñar primero la idea:\n",
        "* Se necesitará inicialmente un espacio (textarea) para poder escribir el prompt de entrada\n",
        "* También deberá existir un espacio (textarea) para que se pueda leer la respuesta\n",
        "* Asingar un título no es mala idea, identificará a la aplicación web\n",
        "* Y también una descripción de la aplicación para darle elegancia\n",
        "* Se puede indicar como serían unos ejemplos de prompt a utiizar\n",
        "\n",
        "Todos estos elementos serán útiles, pero realmente, lo mas importante es saber a que función se le hará responsable de recibir los valores, y que también nos devolverá una respuesta, la función a utilizar será la que se denominó como **preguntar_a_dolly**\n",
        "\n"
      ],
      "metadata": {
        "id": "51aMnPsGSPwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Diseño de la aplicación web\n",
        "# Una variable que definirá una caja para introducir texto\n",
        "caja_de_entrada  = gr.Textbox( label = \"Escribe Prompt Aqui\" , lines = 6 )\n",
        "# Otra variable que definirá una caja para mostrar texto\n",
        "caja_de_salida   = gr.Textbox( label = \"Respuesta\"           , lines = 3 )\n",
        "# Una variable más para darle un título a la aplicación web\n",
        "titulo_de_mi_app = \"Mi tutor IA de matemáticas\"\n",
        "# Podría ser útil usar una variable para mostrar la descripción de la aplicación\n",
        "descripcion_app  = \"Herramienta para aprender de matemáticas con Dolly\"\n",
        "# Un conjunto de ejemplos para poder utilizar como entradas de textos\n",
        "ejemplos         = [\n",
        "    \"Explicame el teorema de Pitágoras\",\n",
        "    \"Explícame la suma de Gauss\"\n",
        "]\n",
        "# La agrupación de todo en una sola interfaz de gradio\n",
        "interfaz = gr.Interface(\n",
        "    fn            = preguntar_a_dolly   ,\n",
        "    inputs        = [ caja_de_entrada ] ,\n",
        "    outputs       = [ caja_de_salida  ] ,\n",
        "    title         = titulo_de_mi_app    ,\n",
        "    description   = descripcion_app     ,\n",
        "    examples      = ejemplos            ,\n",
        "    flagging_mode = \"never\"               # Desaparece un botón llamado Flag\n",
        ")"
      ],
      "metadata": {
        "id": "5i3eqkWHCHeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando la aplicación web\n",
        "\n"
      ],
      "metadata": {
        "id": "8EMQONFlIQlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El diseño que ya está listo debe ser ejecutado y puede ser también publicado, la herramienta grado permite utilziar la interfaz creada a travez de un tunel, publicando la interfaz y haciendola accesible a mas usuarios a través de Internet por lo que brindará una url para poder compartirla"
      ],
      "metadata": {
        "id": "ztqKbhhXTsYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lanzamiento de la aplicación web\n",
        "interfaz.launch( share = True )"
      ],
      "metadata": {
        "id": "NYXB4e54DQt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finalizando la aplicación web"
      ],
      "metadata": {
        "id": "YjM80WEAIbeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando ya se ha probado la aplicación es correcto detener el servicio para que no se desperdicie el tiempo de uso, tanto de las unidades de CPU de Google Colab, como el servicio de publicación de la herramienta del tunel al sitio de gradio"
      ],
      "metadata": {
        "id": "9cwB-HOiVcMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Detener la aplciación web\n",
        "interfaz.close()"
      ],
      "metadata": {
        "id": "ZVyKACGfEpC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probando otra interfaz"
      ],
      "metadata": {
        "id": "FT-lsPol2dgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio tiene la facultad de proveer otro tipo de interfaces, existe una interfaz tipo chat, la cual sería mas familiar para cuando se trabaja con un modelo largo de lenguaje, pero necesita una funcion que recibe dos parámetros, los parámetros son el mensaje y el historial de mensajes"
      ],
      "metadata": {
        "id": "39zVCYlt73Yh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creando una función envolvedora"
      ],
      "metadata": {
        "id": "5Z46Neha83Ik"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crearemos una función que nos dará las repsuestas, pero recibirá dos parámetros y no utilizará el historial en este ejercicio simple"
      ],
      "metadata": {
        "id": "xt_p5SeR8Mf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def respuestas(mensaje, historial):\n",
        "    return preguntar_a_dolly(mensaje)"
      ],
      "metadata": {
        "id": "LyayAEOn2hwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diseñando la interfaz de chat"
      ],
      "metadata": {
        "id": "dFzOKRTg89X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luego crearemos una interfaz de gradio... ocupará muy pocos parámetros"
      ],
      "metadata": {
        "id": "44s7nSTg8aoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = gr.ChatInterface(\n",
        "    respuestas      ,\n",
        "    type=\"messages\" ,\n",
        "    autofocus=False\n",
        ")"
      ],
      "metadata": {
        "id": "mdgXLKYe8V50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Lanzando el chat"
      ],
      "metadata": {
        "id": "ixUp1N_H9G8j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y lanzaremos la interfaz para probarlo"
      ],
      "metadata": {
        "id": "xUsjsitK8mjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.launch( share = True)"
      ],
      "metadata": {
        "id": "m6Qm5Z6V5tjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finalizando el chat"
      ],
      "metadata": {
        "id": "M4kgBJlA9TCx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No hay que olvidar cerrar la interfaz cuando ya no la usemos"
      ],
      "metadata": {
        "id": "B5KFGbCj8sxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat.close()"
      ],
      "metadata": {
        "id": "IwXVy3AN2_Er"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
